# 专业网页数据采集与分析系统

## 项目简介

这是一个专业的网页数据采集和分析系统，专门用于从指定网页中采集日期（期数）、关键词和波色等特定数据，并进行统计分析。

## 主要功能

### 🕷️ 数据采集功能
- 从CSV文件中读取目标链接
- 自动去重处理，避免重复采集
- 支持多种数据提取策略（表格解析、元素匹配）
- 智能编码检测，处理各种字符编码
- 请求失败自动重试机制
- 随机延迟，避免频繁请求被封

### 📊 数据分析功能
- 波色频次统计和百分比分析
- 关键词出现频率统计
- 数据趋势分析和可视化
- 自动生成统计图表（柱状图、饼图、趋势图）
- 导出多种格式报告（CSV、JSON、TXT）

### 🎯 数据采集目标
- **日期期数**: 支持多种日期格式（YYYY-MM-DD、第X期等）
- **关键词**: 如"必中两波"、"精选两波"等
- **波色**: 红波、绿波、蓝波等颜色分类

## 项目结构

```
project/
├── data/                    # 数据目录
│   ├── links.csv           # 输入链接文件
│   ├── results.csv         # 采集结果文件  
│   ├── color_statistics.csv # 波色统计结果
│   ├── color_statistics.json # JSON格式统计
│   ├── analysis_report.txt  # 分析报告
│   ├── color_statistics.png # 统计图表
│   └── color_trends.png     # 趋势图表
├── scripts/                 # 脚本目录
│   ├── crawler.py          # 爬虫脚本
│   └── analysis.py         # 分析脚本
├── requirements.txt         # 依赖包列表
├── run.py                  # 主运行脚本
└── README.md               # 项目说明
```

## 快速开始

### 1. 环境准备

确保已安装Python 3.7或更高版本。

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

或者运行主程序后选择"安装依赖包"选项。

### 3. 准备数据

将包含链接的CSV文件命名为`links.csv`，放置在`data/`目录中。

CSV文件格式示例：
```csv
url
https://example1.com
https://example2.com
https://example3.com
```

### 4. 运行程序

```bash
python run.py
```

然后根据菜单提示选择操作：
- 选项1：运行数据采集爬虫
- 选项2：运行数据分析程序
- 选项3：查看数据文件状态
- 选项4：安装依赖包
- 选项5：查看项目结构

## 详细使用说明

### 数据采集

1. **准备链接文件**: 将目标网页链接保存到`data/links.csv`
2. **运行爬虫**: 执行`python run.py`，选择选项1
3. **等待完成**: 程序会自动处理所有链接并保存结果

爬虫特性：
- 自动去重：相同的链接只会采集一次
- 编码适配：自动检测网页编码
- 错误处理：网络异常时自动重试
- 进度显示：实时显示采集进度

### 数据分析

数据采集完成后，可以进行分析：

1. **运行分析程序**: 选择选项2
2. **查看报告**: 程序会生成多种格式的分析报告

分析输出：
- `color_statistics.csv`: 波色统计数据
- `color_statistics.json`: JSON格式统计
- `analysis_report.txt`: 文本格式综合报告
- `color_statistics.png`: 统计图表
- `color_trends.png`: 趋势分析图

## 技术特性

### 爬虫技术
- **请求库**: requests + Session管理
- **解析引擎**: BeautifulSoup + lxml
- **编码处理**: chardet自动检测
- **进度显示**: tqdm进度条
- **异常处理**: 完善的错误处理机制

### 数据分析
- **数据处理**: pandas DataFrame
- **图表生成**: matplotlib + seaborn
- **统计分析**: 频次统计、百分比计算
- **趋势分析**: 时间序列分析

### 代码设计
- **面向对象**: 模块化设计，便于维护
- **中文注释**: 详细的中文注释说明
- **错误处理**: 完善的异常处理机制
- **配置灵活**: 可根据需要调整参数

## 自定义配置

### 修改采集规则

编辑`scripts/crawler.py`中的解析方法：

```python
def parse_page_data(self, html_content, url):
    # 在这里添加自定义的数据提取逻辑
    pass
```

### 调整关键词匹配

修改关键词列表：

```python
keywords = ['必中两波', '精选两波', '推荐两波', '热门两波']
```

### 修改波色分类

调整波色识别规则：

```python
colors = ['红波', '绿波', '蓝波']
```

## 注意事项

### 使用规范
1. **遵守robots.txt**: 检查目标网站的爬虫协议
2. **控制频率**: 避免对服务器造成过大压力
3. **尊重版权**: 仅用于学习和研究目的
4. **数据隐私**: 不采集敏感个人信息

### 技术限制
1. **网站结构**: 需要根据具体网站调整解析规则
2. **反爬机制**: 某些网站可能有反爬虫措施
3. **动态内容**: 不支持JavaScript渲染的动态内容
4. **数据格式**: 需要目标网站有相对固定的数据格式

### 故障排除

**常见问题**：

1. **链接无法访问**
   - 检查网络连接
   - 确认链接格式正确
   - 查看是否需要登录或验证

2. **数据提取失败**
   - 检查网页结构是否发生变化
   - 调整解析规则
   - 查看网页源码确认数据位置

3. **依赖包安装失败**
   - 更新pip：`pip install --upgrade pip`
   - 使用国内源：`pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/`

## 系统要求

- **操作系统**: Windows/Linux/macOS
- **Python版本**: 3.7+
- **内存**: 建议2GB以上
- **存储**: 根据数据量而定，建议预留足够空间

## 更新日志

### v1.0.0 (2025-06)
- 初始版本发布
- 基础爬虫功能
- 数据统计分析
- 图表生成功能
- 用户友好的菜单界面

## 许可证

本项目仅供学习和研究使用，请勿用于商业用途。

## 技术支持

如有问题或建议，请：
1. 检查本README文档
2. 查看代码中的详细注释
3. 根据错误信息进行故障排除

---

**免责声明**: 本工具仅供学习研究使用，使用者需遵守相关法律法规和网站使用条款，对使用本工具产生的任何后果自行承担责任。 